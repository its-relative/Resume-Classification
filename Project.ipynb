{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets get the Resumes and put them in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'resumes.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory containing the resumes\n",
    "base_dir = 'resumes categorised'\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Walk through the directory structure\n",
    "for category in os.listdir(base_dir):\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        for root, _, files in os.walk(category_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read()\n",
    "                        data.append({'Content': content, 'Category': category})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file with an escape character for any special characters\n",
    "df.to_csv('resumes.csv', index=False, escapechar='\\\\')\n",
    "\n",
    "print(\"CSV file 'resumes.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the required dependencies to see the dataframe that will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting importlib\n",
      "  Downloading importlib-1.0.4.zip (7.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[1 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%pip install importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-docx in /home/its_relative/.local/lib/python3.10/site-packages (1.1.2)\n",
      "Requirement already satisfied: PyPDF2 in /home/its_relative/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Collecting textract\n",
      "  Downloading textract-1.6.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/its_relative/.local/lib/python3.10/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/its_relative/.local/lib/python3.10/site-packages (from python-docx) (4.11.0)\n",
      "Collecting argcomplete~=1.10.0 (from textract)\n",
      "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting chardet==3.* (from textract)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting docx2txt~=0.8 (from textract)\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting extract-msg<=0.29.* (from textract)\n",
      "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pdfminer.six==20191110 (from textract)\n",
      "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting python-pptx~=0.6.18 (from textract)\n",
      "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting six~=1.12.0 (from textract)\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting xlrd~=1.2.0 (from textract)\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pycryptodome (from pdfminer.six==20191110->textract)\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting sortedcontainers (from pdfminer.six==20191110->textract)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/its_relative/.local/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.4.1)\n",
      "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: olefile>=0.46 in /usr/lib/python3/dist-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Collecting tzlocal>=2.1 (from extract-msg<=0.29.*->textract)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
      "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /usr/lib/python3/dist-packages (from python-pptx~=0.6.18->textract) (9.0.1)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
      "Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: docx2txt, compressed-rtf\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=57dfd1a940c8d934e1d7a1e66cea584026c4a778467db08027426b2bf8d81f8b\n",
      "  Stored in directory: /home/its_relative/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
      "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6186 sha256=905acf0466031a62483c1078f5401b5b0ed1d66f8141d350ba279873409c8f15\n",
      "  Stored in directory: /home/its_relative/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
      "Successfully built docx2txt compressed-rtf\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: SpeechRecognition, sortedcontainers, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, tzlocal, six, pycryptodome, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.2.0 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 pdfminer.six-20191110 pycryptodome-3.20.0 python-pptx-0.6.23 six-1.12.0 sortedcontainers-2.4.0 textract-1.6.5 tzlocal-5.2 xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx PyPDF2 textract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: React Dev_Krishna Kanth_Musquare Technologies.docx\n",
      "Read file React Dev_Krishna Kanth_Musquare Technologies.docx with category React\n",
      "Processing file: React Developer_PavasGoswami.doc\n",
      "Read file React Developer_PavasGoswami.doc with category React\n",
      "Processing file: React Developer_Haripriya.docx\n",
      "Read file React Developer_Haripriya.docx with category React\n",
      "Processing file: React Developer_Sarala Madasu-converted.docx\n",
      "Read file React Developer_Sarala Madasu-converted.docx with category React\n",
      "Processing file: React Developer_Kamalakar Reddy.docx\n",
      "Read file React Developer_Kamalakar Reddy.docx with category React\n",
      "Processing file: .~lock.React Developer_PavasGoswami.doc#\n",
      "Skipping file: .~lock.React Developer_PavasGoswami.doc# (unsupported format)\n",
      "Processing file: React Developer_Thirupathiamma.docx\n",
      "Read file React Developer_Thirupathiamma.docx with category React\n",
      "Processing file: React Dev_Krishna Kanth.docx\n",
      "Read file React Dev_Krishna Kanth.docx with category React\n",
      "Processing file: React Developer_Naveen sadhu.docx\n",
      "Read file React Developer_Naveen sadhu.docx with category React\n",
      "Processing file: React Developer_Deepakreddy.docx\n",
      "Read file React Developer_Deepakreddy.docx with category React\n",
      "Processing file: React Developer_Pragnya.docx\n",
      "Read file React Developer_Pragnya.docx with category React\n",
      "Processing file: React Developer_Vinay Reddy.doc\n",
      "Read file React Developer_Vinay Reddy.doc with category React\n",
      "Processing file: Nazeer Basha.doc\n",
      "Read file Nazeer Basha.doc with category SQL Developer Lightning insight\n",
      "Processing file: premsai.docx\n",
      "Read file premsai.docx with category SQL Developer Lightning insight\n",
      "Processing file: PSyamKumar[2_3].docx\n",
      "Read file PSyamKumar[2_3].docx with category SQL Developer Lightning insight\n",
      "Processing file: Buddha Vamsi.docx\n",
      "Read file Buddha Vamsi.docx with category SQL Developer Lightning insight\n",
      "Processing file: Ramalakshmi K.docx\n",
      "Read file Ramalakshmi K.docx with category SQL Developer Lightning insight\n",
      "Processing file: AradhanaTripathi[4_0].docx\n",
      "Read file AradhanaTripathi[4_0].docx with category SQL Developer Lightning insight\n",
      "Processing file: Vinod B.docx\n",
      "Read file Vinod B.docx with category SQL Developer Lightning insight\n",
      "Processing file: Rajupavanakumari[2_10].docx\n",
      "Read file Rajupavanakumari[2_10].docx with category SQL Developer Lightning insight\n",
      "Processing file: kamballapradeep.docx\n",
      "Read file kamballapradeep.docx with category SQL Developer Lightning insight\n",
      "Processing file: Neeraj Mishra.docx\n",
      "Read file Neeraj Mishra.docx with category SQL Developer Lightning insight\n",
      "Processing file: RameshNataru[3_4].docx\n",
      "Read file RameshNataru[3_4].docx with category SQL Developer Lightning insight\n",
      "Processing file: Tatikonda Kiran Kumar.doc\n",
      "Read file Tatikonda Kiran Kumar.doc with category SQL Developer Lightning insight\n",
      "Processing file: Anil kumar.docx\n",
      "Read file Anil kumar.docx with category SQL Developer Lightning insight\n",
      "Processing file: Priyanka L.doc\n",
      "Read file Priyanka L.doc with category SQL Developer Lightning insight\n",
      "Processing file: Naresh Babu Cherukuri_Hexaware.doc\n",
      "Read file Naresh Babu Cherukuri_Hexaware.doc with category workday resumes\n",
      "Processing file: Himaja G_(Hexaware).docx\n",
      "Read file Himaja G_(Hexaware).docx with category workday resumes\n",
      "Processing file: Harikrishna Akula_Hexaware.doc\n",
      "Read file Harikrishna Akula_Hexaware.doc with category workday resumes\n",
      "Processing file: ShireeshKumar_Hexaware.doc\n",
      "Read file ShireeshKumar_Hexaware.doc with category workday resumes\n",
      "Processing file: Hari Krishna M_Hexaware.doc\n",
      "Read file Hari Krishna M_Hexaware.doc with category workday resumes\n",
      "Processing file: ChinnaSubbarayuduM_Hexaware.docx\n",
      "Read file ChinnaSubbarayuduM_Hexaware.docx with category workday resumes\n",
      "Processing file: Sri Krishna S_Hexaware.doc\n",
      "Read file Sri Krishna S_Hexaware.doc with category workday resumes\n",
      "Processing file: SSKumar_Hexaware.docx\n",
      "Read file SSKumar_Hexaware.docx with category workday resumes\n",
      "Processing file: Srikanth-Hexaware.docx\n",
      "Read file Srikanth-Hexaware.docx with category workday resumes\n",
      "Processing file: Punugoti Swetha_Hexaware.doc\n",
      "Read file Punugoti Swetha_Hexaware.doc with category workday resumes\n",
      "Processing file: Venkateswarlu B_Hexaware.doc\n",
      "Read file Venkateswarlu B_Hexaware.doc with category workday resumes\n",
      "Processing file: Jyotiverma_Heaware.docx\n",
      "Read file Jyotiverma_Heaware.docx with category workday resumes\n",
      "Processing file: MooraboyinaGuravaiah_Hexaware.docx\n",
      "Read file MooraboyinaGuravaiah_Hexaware.docx with category workday resumes\n",
      "Processing file: Hima Mendu_Hexaware.doc\n",
      "Read file Hima Mendu_Hexaware.doc with category workday resumes\n",
      "Processing file: J. Sumanth Royal_Hexaware.doc\n",
      "Read file J. Sumanth Royal_Hexaware.doc with category workday resumes\n",
      "Processing file: Vinay Kumar_Hexaware.docx\n",
      "Read file Vinay Kumar_Hexaware.docx with category workday resumes\n",
      "Processing file: RahulM_Hexaware.docx\n",
      "Read file RahulM_Hexaware.docx with category workday resumes\n",
      "Processing file: Madeeswar A_Hexaware.doc\n",
      "Read file Madeeswar A_Hexaware.doc with category workday resumes\n",
      "Processing file: Gopi Krishna_Hexaware.docx\n",
      "Read file Gopi Krishna_Hexaware.docx with category workday resumes\n",
      "Processing file: P V Sai Krishna_ Hexaware.docx\n",
      "Read file P V Sai Krishna_ Hexaware.docx with category workday resumes\n",
      "Processing file: RameshP_Hexaware.docx\n",
      "Read file RameshP_Hexaware.docx with category workday resumes\n",
      "Processing file: Peoplesoft FSCM_PriyabrataHota.docx\n",
      "Read file Peoplesoft FSCM_PriyabrataHota.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Finance_Arun Venu.doc\n",
      "Read file Peoplesoft Finance_Arun Venu.doc with category Peoplesoft resumes\n",
      "Processing file: PeopleSoft DBA_Vivekanand Sayana.docx\n",
      "Read file PeopleSoft DBA_Vivekanand Sayana.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_AnubhavSingh.docx\n",
      "Read file Peoplesoft Admin_AnubhavSingh.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Finance_Pritam Biswas.doc\n",
      "Read file Peoplesoft Finance_Pritam Biswas.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_SirazuddinMohammad.docx\n",
      "Read file Peoplesoft Admin_SirazuddinMohammad.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft FSCM_R Ahmed.doc\n",
      "Read file Peoplesoft FSCM_R Ahmed.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Read file Peoplesoft Admin_G Ananda Rayudu.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft FSCM_SUJATHA.docx\n",
      "Read file Peoplesoft FSCM_SUJATHA.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_srinivasarao.doc\n",
      "Read file Peoplesoft Admin_srinivasarao.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_Gangareddy.doc\n",
      "Read file Peoplesoft Admin_Gangareddy.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Finance_Rahul Ahuja.doc\n",
      "Read file Peoplesoft Finance_Rahul Ahuja.doc with category Peoplesoft resumes\n",
      "Processing file: Resume_Subha Santosh_Peoplesoft FSCM.docx\n",
      "Read file Resume_Subha Santosh_Peoplesoft FSCM.docx with category Peoplesoft resumes\n",
      "Processing file: PeopleSoft DBA_Ganesh Alladi.doc\n",
      "Read file PeopleSoft DBA_Ganesh Alladi.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft FSCM_HariNarayana.docx\n",
      "Read file Peoplesoft FSCM_HariNarayana.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft FSCM_Murali.docx\n",
      "Read file Peoplesoft FSCM_Murali.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_Priyanka Ramadoss.doc\n",
      "Read file Peoplesoft Admin_Priyanka Ramadoss.doc with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_Murali.docx\n",
      "Read file Peoplesoft Admin_Murali.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_Varkala Vikas.docx\n",
      "Read file Peoplesoft Admin_Varkala Vikas.docx with category Peoplesoft resumes\n",
      "Processing file: Peoplesoft Admin_Vinod Akkala.doc\n",
      "Read file Peoplesoft Admin_Vinod Akkala.doc with category Peoplesoft resumes\n",
      "Processing file: Internship_Susovan Bag_Musquare Technologies.docx\n",
      "Read file Internship_Susovan Bag_Musquare Technologies.docx with category internship\n",
      "Processing file: Internship_Ravali_Musquare Technologies (1).docx\n",
      "Read file Internship_Ravali_Musquare Technologies (1).docx with category internship\n",
      "Processing file: Reactjs Developer_MD Khizaruddin Rauf _Musquare Technologies.docx\n",
      "Read file Reactjs Developer_MD Khizaruddin Rauf _Musquare Technologies.docx with category Reactjs\n",
      "Processing file: Reactjs Developer_M Lokesh Babu_Musquare Technologies.docx\n",
      "Read file Reactjs Developer_M Lokesh Babu_Musquare Technologies.docx with category Reactjs\n",
      "Processing file: Reactjs Developer_Prabakaran_Musquare Technologies.pdf\n",
      "Read file Reactjs Developer_Prabakaran_Musquare Technologies.pdf with category Reactjs\n",
      "Processing file: Reactjs Developer_Pranish Sonone_Musquare Technologies.docx\n",
      "Read file Reactjs Developer_Pranish Sonone_Musquare Technologies.docx with category Reactjs\n",
      "Processing file: Reactjs Developer_kambala sai surendra_Musquare Technologies.docx\n",
      "Read file Reactjs Developer_kambala sai surendra_Musquare Technologies.docx with category Reactjs\n",
      "Processing file: React JS Developer_KotaniDurgaprasad[3_1] (1)-converted.docx\n",
      "Read file React JS Developer_KotaniDurgaprasad[3_1] (1)-converted.docx with category Reactjs\n",
      "Processing file: React JS Developer_AnjaniPriyadarshini.doc\n",
      "Read file React JS Developer_AnjaniPriyadarshini.doc with category Reactjs\n",
      "Processing file: Reactjs Developer_Ranga Gaganam_Musquare Technologies.docx\n",
      "Read file Reactjs Developer_Ranga Gaganam_Musquare Technologies.docx with category Reactjs\n",
      "Processing file: Reactjs Developer_Shaik Abdul Sharuk_Musquare Technologies.docx\n",
      "Read file Reactjs Developer_Shaik Abdul Sharuk_Musquare Technologies.docx with category Reactjs\n",
      "Processing file: Reactjs Developer_M Lokesh.docx\n",
      "Read file Reactjs Developer_M Lokesh.docx with category Reactjs\n",
      "Processing file: React JS Developer_Venkatalakshmi (1)-converted.docx\n",
      "Read file React JS Developer_Venkatalakshmi (1)-converted.docx with category Reactjs\n",
      "Resumes data saved to CSV file successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import textract\n",
    "\n",
    "# Define the base directory containing the resumes\n",
    "base_dir = 'resumes categorised'\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "def read_text(file):\n",
    "    try:\n",
    "        text = textract.process(file)\n",
    "        return text.decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f'Error extracting text from {file}: {e}')\n",
    "        return None\n",
    "\n",
    "# Walk through the directory structure\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file_name in files:\n",
    "        # Print the file name for debugging purposes\n",
    "        print(f'Processing file: {file_name}')\n",
    "        \n",
    "        # Extract the category from the folder name\n",
    "        category = os.path.basename(root)\n",
    "        \n",
    "        # Handle different file types\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        if file_name.endswith('.docx') or file_name.endswith('.doc'):\n",
    "            content = read_text(file_path)\n",
    "        elif file_name.endswith('.pdf'):\n",
    "            content = read_text(file_path)\n",
    "        else:\n",
    "            print(f'Skipping file: {file_name} (unsupported format)')\n",
    "            continue\n",
    "        \n",
    "        if content is not None:\n",
    "            data.append({'Resume': content, 'Category': category})\n",
    "            print(f'Read file {file_name} with category {category}')\n",
    "        else:\n",
    "            print(f'Failed to read file {file_name}. Content is None.')\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('all_resumes.csv', index=False)\n",
    "print('Resumes data saved to CSV file successfully!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets read the Dataset and check its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"resumes_data.csv\")\n",
    "\n",
    "df = data.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ui-Developer/ React JS Developer \\n\\nNAME: KRI...</td>\n",
       "      <td>React</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n [pic]\\n\\nPROFILE\\n\\n Searching for the oppo...</td>\n",
       "      <td>React</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARIPRIYA BATTINA \\n\\nExperience as UI Develop...</td>\n",
       "      <td>React</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARALA MADASU\\n\\nSARALA MADASU\\n\\n 204,Sri ge...</td>\n",
       "      <td>React</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAMALAKAR REDDY. A \\n\\nLinked In: https://www....</td>\n",
       "      <td>React</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>\\n                              CURRICULUM VIT...</td>\n",
       "      <td>Reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ranga Gaganam  \\n\\n\\n\\n \\n\\nProfessional\\n\\n \\...</td>\n",
       "      <td>Reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SHAIK ABDUL SHARUK   \\n\\n2 years’ Experience i...</td>\n",
       "      <td>Reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>MAREEDU LOKESH BABU\\n\\n\\n\\nPROFESSIONAL OVERVI...</td>\n",
       "      <td>Reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Venkatalakshmi Pedireddy\\n\\nSoftware Developer...</td>\n",
       "      <td>Reactjs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Resume Category\n",
       "0   Ui-Developer/ React JS Developer \\n\\nNAME: KRI...    React\n",
       "1   \\n [pic]\\n\\nPROFILE\\n\\n Searching for the oppo...    React\n",
       "2   HARIPRIYA BATTINA \\n\\nExperience as UI Develop...    React\n",
       "3   SARALA MADASU\\n\\nSARALA MADASU\\n\\n 204,Sri ge...    React\n",
       "4   KAMALAKAR REDDY. A \\n\\nLinked In: https://www....    React\n",
       "..                                                ...      ...\n",
       "74  \\n                              CURRICULUM VIT...  Reactjs\n",
       "75  Ranga Gaganam  \\n\\n\\n\\n \\n\\nProfessional\\n\\n \\...  Reactjs\n",
       "76  SHAIK ABDUL SHARUK   \\n\\n2 years’ Experience i...  Reactjs\n",
       "77  MAREEDU LOKESH BABU\\n\\n\\n\\nPROFESSIONAL OVERVI...  Reactjs\n",
       "78  Venkatalakshmi Pedireddy\\n\\nSoftware Developer...  Reactjs\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
